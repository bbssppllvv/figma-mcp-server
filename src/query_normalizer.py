#!/usr/bin/env python3
"""
Query Normalizer - ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ Ð¶Ð¸Ð²Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð² ÐºÐ°Ð½Ð¾Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ñ‹ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
"""

import yaml
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class QueryNormalizer:
    """ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ð¾Ð² Ð¸ Ð°Ð»Ð¸Ð°ÑÐ¾Ð²"""
    
    def __init__(self, aliases_file: str = "config/query_aliases.yaml"):
        self.aliases_file = Path(aliases_file)
        self.aliases: Dict[str, str] = {}
        self.load_aliases()
    
    def load_aliases(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ð¾Ð² Ð¸Ð· YAML Ñ„Ð°Ð¹Ð»Ð°"""
        try:
            if not self.aliases_file.exists():
                logger.warning(f"Aliases file not found: {self.aliases_file}")
                return
                
            with open(self.aliases_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ Ð°Ð»Ð¸Ð°ÑÐ¾Ð² Ð² Ð¾Ð´Ð¸Ð½ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
            for category, aliases in data.items():
                if isinstance(aliases, dict):
                    for alias, canonical in aliases.items():
                        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ ÐºÐ»ÑŽÑ‡Ð¸ Ð´Ð»Ñ case-insensitive Ð¿Ð¾Ð¸ÑÐºÐ°
                        self.aliases[alias.lower().strip()] = canonical
            
            logger.info(f"Loaded {len(self.aliases)} query aliases")
            
        except Exception as e:
            logger.error(f"Failed to load aliases: {e}")
    
    def normalize_query(self, query: str) -> Tuple[str, List[str]]:
        """
        ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°Ñ ÐºÐ°Ð½Ð¾Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ñ‚ÐµÑ€Ð¼Ð¸Ð½ Ð¸ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹
        
        Returns:
            Tuple[str, List[str]]: (normalized_query, additional_terms)
        """
        original_query = query.strip()
        normalized_query = original_query
        additional_terms = []
        
        # Case-insensitive Ð¿Ð¾Ð¸ÑÐº Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ
        query_lower = original_query.lower()
        if query_lower in self.aliases:
            canonical = self.aliases[query_lower]
            normalized_query = canonical
            additional_terms.append(original_query)  # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð» ÐºÐ°Ðº Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ‚ÐµÑ€Ð¼Ð¸Ð½
            logger.info(f"Query normalized: '{original_query}' -> '{canonical}'")
        
        # ÐŸÐ¾Ð¸ÑÐº Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ñ… ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ (ÐµÑÐ»Ð¸ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾)
        elif not normalized_query or normalized_query == original_query:
            partial_matches = self._find_partial_matches(query_lower)
            if partial_matches:
                # Ð‘ÐµÑ€ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐµÐµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ
                best_match = partial_matches[0]
                normalized_query = self.aliases[best_match]
                additional_terms.extend([original_query, best_match])
                logger.info(f"Query partially normalized: '{original_query}' -> '{normalized_query}' (via '{best_match}')")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°
        additional_terms.extend(self._generate_variations(normalized_query))
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº
        seen = set()
        unique_additional = []
        for term in additional_terms:
            if term not in seen and term != normalized_query:
                seen.add(term)
                unique_additional.append(term)
        
        return normalized_query, unique_additional
    
    def _find_partial_matches(self, query_lower: str) -> List[str]:
        """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð² Ð°Ð»Ð¸Ð°ÑÐ°Ñ…"""
        matches = []
        
        for alias in self.aliases.keys():
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ÑÑ Ð»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð² Ð°Ð»Ð¸Ð°ÑÐµ Ð¸Ð»Ð¸ Ð½Ð°Ð¾Ð±Ð¾Ñ€Ð¾Ñ‚
            if query_lower in alias or alias in query_lower:
                matches.append(alias)
        
        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ (Ð±Ð¾Ð»ÐµÐµ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð»ÑƒÑ‡ÑˆÐµ)
        matches.sort(key=lambda x: abs(len(x) - len(query_lower)))
        return matches
    
    def _generate_variations(self, term: str) -> List[str]:
        """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ ÑˆÐ¸Ñ€Ð¾ÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°"""
        variations = []
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ figma.
        if term.startswith("figma."):
            clean_term = term[6:]
            variations.append(clean_term)
            
            # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ‚Ð¾Ñ‡ÐºÐ¸, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ Ñ‡Ð°ÑÑ‚ÑŒ
            if "." in clean_term:
                method_name = clean_term.split(".")[-1]
                variations.append(method_name)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ camelCase Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸
        if "_" in term:
            camel_case = self._to_camel_case(term)
            variations.append(camel_case)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ snake_case Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸
        if re.search(r'[A-Z]', term):
            snake_case = self._to_snake_case(term)
            variations.append(snake_case)
        
        return variations
    
    def _to_camel_case(self, snake_str: str) -> str:
        """ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ snake_case Ð² camelCase"""
        components = snake_str.split('_')
        return components[0] + ''.join(word.capitalize() for word in components[1:])
    
    def _to_snake_case(self, camel_str: str) -> str:
        """ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ camelCase Ð² snake_case"""
        s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', camel_str)
        return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()
    
    def get_all_aliases(self) -> Dict[str, str]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð²ÑÐµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ðµ Ð°Ð»Ð¸Ð°ÑÑ‹"""
        return self.aliases.copy()
    
    def add_alias(self, alias: str, canonical: str):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð°Ð»Ð¸Ð°Ñ Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ"""
        self.aliases[alias.lower().strip()] = canonical
        logger.info(f"Added runtime alias: '{alias}' -> '{canonical}'")
    
    def get_stats(self) -> Dict[str, int]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
        return {
            "total_aliases": len(self.aliases),
            "categories": len(set(alias.split()[0] for alias in self.aliases.keys() if " " in alias))
        }


def test_normalizer():
    """Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
    normalizer = QueryNormalizer()
    
    test_queries = [
        "export PNG",
        "OAuth flow", 
        "variables mode",
        "selection change",
        "variant props",
        "post message",
        "figma.variables.setValueForMode",
        "create rectangle",
        "unknown query"
    ]
    
    print("ðŸ” Testing Query Normalizer:")
    print("=" * 50)
    
    for query in test_queries:
        normalized, additional = normalizer.normalize_query(query)
        print(f"'{query}' -> '{normalized}'")
        if additional:
            print(f"  Additional terms: {additional}")
        print()
    
    stats = normalizer.get_stats()
    print(f"ðŸ“Š Stats: {stats['total_aliases']} aliases loaded")


if __name__ == "__main__":
    test_normalizer()
